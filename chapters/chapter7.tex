\chapter{Thesis discussion}\label{chap:chapter7}

In this thesis, I have developed and built upon reliability methods using the Bayesian framework to make these models appliable to maintenance problems in the mining and mineral processing domain. The works in the two main body parts of the thesis were motivated by industry problems---found through my time on industry placements---that were not solvable by using methods from the reliability literature due to incompleteness and noisiness of the industry data. Through the two parts, I address two main \textit{theory-practice gaps} that will support reliability engineers in domains such as mining and mineral processing industry. The first is handling partially observed lifetime data that can be both left-truncated with unknown exposure history and right-censored; a case that naturally arises when units have been repeatedly replaced for many years and only the failure records after a given date are available. The second part looked at the gamma process and how through the Bayesian hierarchical modelling formalism necessary, non-trivial extensions can be included, such as the need to account for measurement error or unit-to-unit variation and how to accommodate wearing surfaces.

In these final pages of the thesis, I start in section~\ref{sec:thesis-summary} by summarising the work from the body of the Thesis and emphasis the key contributions. I then revisit the most significant areas for future work in section~\ref{sec:thesis-future-work}. In section~\ref{sec:thesis-practical}, I discuss the impacts of the work for reliability practitioners in industry and conclude the thesis.
%Finally, Section~\ref{sec:thesis-conclusion} concludes the thesis.

\section{Overview and main discussions} \label{sec:thesis-summary}

Part~\ref{part:one} of the thesis---consisting of chapters~\ref{chap:chapter2} and ~\ref{chap:chapter3}---focused on lifetime analysis, specifically lifetime data that can be both left-truncated with unknown exposure history and right-censored. In chapter~\ref{chap:chapter2}, I developed a Bayesian model for such lifetime data that imputes the true values of the partially observed lifetimes and, along with them, the missing truncation times in order to evaluate the likelihood. I also built upon the method, originally proposed by \citet{kaminskiy2005}, for eliciting a joint prior for the Weibull parameters by embedding it fully within a Bayesian lifetime model so that the prior is properly filtered through the likelihood of the observed data. Using simulated data, I demonstrated the imputation method with both weakly and strongly informative priors, comparing it with the case where exposure times for the left-truncated lifetimes are known and where the left-truncated lifetimes are discarded. Chapter~\ref{chap:chapter2} ended with a small simulation study to evaluate when it is suitable to use the imputation treatment of the left-truncated lifetimes with unknown exposure history.

Left truncation with unknown exposure time is difficult to identify in a dataset and is easy to confuse with simple censoring. It is important to either account for the truncation in the lifetimes that begin before the beginning of the observation period or discard the lifetimes completely; otherwise, the results of the analysis will be biased. However, when formulating the likelihood of the data given the parameters in the usual way---that is, integrating out the censored observation---, there is no obvious way of accounting for the missing truncation times. I have shown that if we instead take the approach of imputing the partially observed censored lifetimes, any lifetimes that begin before the observation period are a case of censoring, and by imputing their values, we can then calculate a corresponding truncation time. I've also shown that this is easily implemented in probabilistic programming languages like Stan.

The second main body chapter of Part~\ref{part:one}, chapter~\ref{chap:chapter3}, applies the methods developed in Chap.~\ref{chap:chapter2} to the industry dataset of idler-frame lifetimes. In the chapter, I analysed the idler-frame lifetimes with an informative prior, imputing the partially observed samples and truncation times to perform inference and retain as much of the information in the dataset as possible. I then showed how, by imputing the partially observed lifetimes in the model, the posterior naturally contains predictive draws for the frames still under test conditioned on their age. Using these draws, I showed how to generate predictive distributions for the RUL of frames still in operation at the end of the observation period and how to generate predictive distributions for the cumulative number of failures going forward. Lastly, in the chapter, I showed how the joint draws of the Weibull parameters can be passed through a cost function to include uncertainty in the analysis when choosing a fixed time replacement interval for the idlers on the conveyor. 

Part~\ref{part:two} of the thesis focused on degradation modelling, mainly using gamma stochastic processes. The first two chapters, chap.~\ref{chap:chapter4} and~\ref{chap:chapter5}, focused on theoretical developments of the gamma process model to include noisy observations and unit-to-unit variability. The third and final chapter, chap.~\ref{chap:chapter6}, applied the gamma process to the industry dataset for conveyor belt wear and made comparisons with a linear general path model.

Chapter~\ref{chap:chapter4} organises some of the literature on the noisy gamma process by showing how the Bayesian hierarchical formalism allows us to frame a model for a noisy gamma stochastic process in a tractable and transparent manner. Decomposing the noisy degradation model into data, process, and parameter models removes the need for complex deconvolution that requires the evaluation of, or approximations to, multidimensional integrals. The chapter also presents a reparametrisation of the gamma process in terms of the mean $\mu$ and coefficient of variation $\nu$, which simplifies prior specification since $\mu$ is clearly interpretable as the average wear rate and $\nu$ is the volatility of the process. In addition, the parameters $\mu$ and $\nu$ are orthogonal, which has desirable computational benefits.

I demonstrated the hierarchical noisy gamma process with parameters $\mu$ and $\nu$ on a simulated dataset and, in doing so, highlighted a presymptomatic non-identifiability between the measurement error and the volatility of the gamma process when the model is fit to a small number of noisy observations. This observation is particularly important in reliability applications since degradation datasets are often small. The weak identifiability between the standard deviation of the measurement error and the coefficient of variation of the gamma process highlights the importance of incorporating domain knowledge or supplementary data into the model or the partial pooling of information between similar units.

Chapter~\ref{chap:chapter5} then showed how the same BHM for the noisy gamma process can be naturally extended to include unit-to-unit variability from multiple noisily-observed degradation signals and how allowing some parameters to vary determines how information is shared between observational units. The proposed parameterisation in terms of $\mu$ and $\nu$ makes expansions of the model, such as unit-to-unit variability, more obvious, i.e. how similar do we expect the units to be in terms of their wear rate, their volatility, or both? In Chap.~\ref{chap:chapter5}, I fitted several variations of the noisy gamma process with unit-to-unit variability to experimental crack growth data with added noise. I demonstrated how to check and compare the models in a fully Bayesian framework using posterior predictive distributions and $elppd$ and cross-validation. In the last part of the chapter, I show how to construct failure time distributions, with uncertainty, for units that are under test but have not failed and for new units.

In Chapter~\ref{chap:chapter6}, I analysed the wear profile dataset from an iron ore conveyor's belt. To model the profiles, I proposed a functional data analysis approach, where the smooth B-spline functions that describe the wear profile at each observation time evolve according to a degradation model. I compare, side-by-side, a noisy gamma process and a linear general path model for the evolution of the spline coefficients. To the best of my knowledge, there is no work of functional degradation models in the literature. Using the functional models, I show how to forecast the degradation profile of the belt into the future and how to construct failure time distributions that account for the uncertainty in the wear profile along the length of the belt.

In all of these chapters, I follow the precepts of good practice in the Bayesian statistical workflow and demonstrate: carefully constructing informative priors and checking these assumptions through prior predictive checking; assessing models using simulation; checking computation with HMC diagnostics; visualising the posterior through posterior predictive distributions or checking; and comparing models in a fully Bayesian framework. I place a particularly strong emphasis on how to encode prior information since either small sample sizes or weekly informative data (i.e. due to partially observed data or signals obscured by noise) are prominent problems in reliability datasets from the mining industry.

\section{Future directions} \label{sec:thesis-future-work}

\paragraph*{pt.1} The method I propose for imputing the partially observed left-truncated lifetimes and their truncation times needs further investigation. For example, I did not fully separate the issues with the approach due to implementation from those due to breaches in the assumptions made. When implemented in Stan, there appears to be some updating in the imputed truncation times when the lifetime is both left-truncated by the beginning of the observation period and right-censored by its end, even though there should not be any information in the data to inform this parameter. The method could be implemented in Bugs \citep{lunn2012}, where it is possible to include nuisance parameters that are not updated in the MCMC routine to overcome this issue, or the same could be achieved by constructing the MCMC algorithm from scratch. However, in the case of the idler-frames, only one lifetime was left truncated and right censored, so this limitation with the method should not affect results. There are also issues with the approach when the start of the observation period is too close to the origin of the repeated replacement process ($t = 0$). However, the boundary for what is acceptable is not clearly defined. More rigorous simulation would be necessary to identify this boundary.

The approach I have proposed assumes that all units (frames) are identical. However, additional information about the idler frames could be included in the model, such as where along the conveyor they are located---in the impact zone, at the head or tail pulley transitions---or the manufacturer type---which is available for recently installed idlers. It would be both interesting and useful to allow for similar but different groups of idlers to share information, such as the Hierarchical models in Part~\ref{part:two} of the thesis, and to include covariates in the model. Additionally, In the analysis of the idler-frames, there are a number of very short lifetimes that I treat as right-censoring events. These early failures still threaten to cause downtime. The infant mortalities could be included in a mixture model such as in \citet{mittman2013}; however, it would be important to understand how a mixture of lifetime distributions would affect the imputation of the partially observed left-truncated lifetimes and their truncation times.

\paragraph*{pt.2} In fitting the noisy gamma process, there is a point when the noisy observation of the signal obscures the `jumpiness' of the degradation trace, and it is much easier to fit a linear model rather than a stochastic process. More work needs to be done to understand the interplay between the volatility of a degradation signal and its noisy observation. In addition, noisy observations also add uncertainty to weather or not unit-to-unit variability is necessary in the model. For example, if we identify that unit-to-unit variability is present for a non-noisy set of degradation traces, is there a level of measurement error where the conclusion is not the same? A further question is how sensitive are metrics such as $\mbox{elppd}_{\text{CV}}$ in these cases, and would they lead us to the correct model in these circumstances? These questions would need to be explored through simulation, simulating data from a known model and seeing if the model can be identified under different conditions.

In Chapter~\ref{chap:chapter6}, I have shown how FDA can be used to model a one-dimensional degrading surface. There are now companies that perform point cloud scans of a surface. Extending the method to two dimensions would be useful for this type of data. I also highlight in section~\ref{sec:belt-wear-discussion} that the model I propose does not account for large-scale spatial dependence between the spline coefficients. When analysing a two-dimensional dataset with observations on a densely observed grid, it would be interesting to incorporate large-scale spatial effects into the model. One possible way of doing this could be to use a conditional autoregressive (CAR) prior.

\section{Implications for industry practitioners} \label{sec:thesis-practical}

Throughout the thesis, the Bayesian approaches I have presented address real problems in reliability data from the mining and mineral processing sector---retaining the information from lifetimes that are left truncated with unknown exposure history; modelling multiple noisy degradation signals with stochastic degradation models; and modelling the degradation of a wearing surface using functional data analysis. In addition to addressing these practical problems, the Bayesian approaches are implemented in Stan, an accessible and open-source probabilistic programming language, so that the models can be implemented and adjusted easily by a wide audience. Throughout the work, I have stressed the components of what is considered to be a good Bayesian statistical workflow and demonstrated their application in the reliability domain. These include thinking carefully about how a model can be encoded in order to simplify its implementation; evaluating and refining the model and priors through simulation before fitting the data; interpreting uncertainty in the posterior through posterior predictive distributions; propagating this uncertainty through useful utility functions such as cost functions or the failure time distribution; and comparing sets of Bayesian models using $\mbox{elppd}$ and cross-validation methods. In the interests of reproducible research, I provide all of the code to implement the models and perform the analysis of this thesis on a Github repository [Leadbetter et al., 2024] so that other reliability practitioners can follow along, reproduce and apply our work in practice, and adapt the models and workflow to their own industry problems.

Of these Bayesian workflow components, I have focused on defining a well-constructed prior and propagating posterior uncertainty. I've stressed how supplementary information can be included in the analysis through the prior (or directly in the likelihood in the case of section~\ref{sec:comp-sols}) and the benefits when analysing small datasets because this seems to be a common occurrence with reliability data in industry. New monitoring devices promise to supply detailed and large datasets in the future, but good decisions must be made now. Much of the historical datasets are small and messy, and the wealth of industry domain expert knowledge is incredibly helpful in these cases. I've also stressed the demonstration of simple examples of using the posterior of a Bayesian model to inform short and long-term maintenance decisions. Little in the literature guides practitioners on how to incorporate the uncertainty encoded in a posterior distribution into maintenance decisions. More works in Bayesian reliability, like this one, should present examples of this last step in the Bayesian \textit{reliability} workflow.

%\section{Conclusions of the thesis} \label{sec:thesis-conclusion}

%Keep it simple.
# This code evaluates the calibration of the forecast distribution
# generated by the STAN model. For all posible combinations of N 
# step ahead predictions (with a minimum of 5 training observations) 
# I forecast the wear and then calculate the probability integral 
# trasformation(PIT) of the observed UT measurements. The PIT values 
# should theoreticaly be uniforemly distributed if the predictive 
# distribution is well calibrated.

library(rstan)
library(dplyr)
library(stringr)
library(posterior)
library(ggplot2)
library(ggdist)
library(ggpp)
library(data.table)
library(tidyr)
library(tidybayes)

# Stan options
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

# data to fit model
stan_data <- readRDS(
  file = "stan-data.rds"
)
fda_noisy_GP_stan_model <- readRDS(
  file = "compiled-stan-model-gp.rds"
)
fda_LM_stan_model <- readRDS(
  file = "compiled-stan-model-lm.rds"
)

# Students' t for sampling
rstudents_t <- function(n, df, mu, sigma) {
    
    sample_st <- rt(n, df)
    sample <- (sample_st * sigma) + mu

    return(sample)

}

# Sampling functions for rvar
rvar_rgamma <- rfun(rgamma)
rvar_rstudents_t <- rfun(rstudents_t)
rvar_rnorm <- rfun(rnorm)

# Forecast the z_{I + 1, n}
genForecast_gp <- function(stan_fit_obj, t_forecast, t_present){

    post <- as_draws_rvars(stan_fit_obj)

    z_predictions <- post %>%
    spread_rvars(
        y[i, m], 
        mu[m], 
        nu[m], 
        phi
    ) %>%
    filter(i == max(i)) %>%
    mutate(
        t_step = t_forecast - t_present,
        y_jump = rvar_rgamma(
            8, 
            shape = (t_step / nu^2), 
            rate = (1 / nu^2)
        ),
        y_forecast_std = y + y_jump,
        y_forecast = y_forecast_std * mu ,
        y_forecast_noisy = rvar_rstudents_t(
            n = 8,
            df = 10,
            mu = y_forecast,
            sigma = phi * y_forecast
        )
    ) %>% 
    summarise(z_forecast = y_forecast_noisy %**% t(stan_data$B)) %>% 
    .$z_forecast %>%
    as.data.frame() %>%
    pivot_longer(everything()) %>%
    mutate(
        n = 1:stan_data$N,
        sigma = post$sigma,
        z_noisy = rvar_rnorm(length(value), mean = value, sd = sigma)
    )

    return(z_predictions)
}

genForecast_lm <- function(stan_fit_obj, t_forecast){

    post <- as_draws_rvars(stan_fit_obj)

    z_predictions <- post %>%
    spread_rvars(
        mu[m], 
        phi
    ) %>%
    mutate(
        y_forecast = mu * t_forecast,
        y_forecast_noisy = rvar_rstudents_t(
            n = 8,
            df = 10,
            mu = y_forecast,
            sigma = phi * y_forecast
        )
    ) %>% 
    summarise(z_forecast = y_forecast_noisy %**% t(stan_data$B)) %>% 
    .$z_forecast %>%
    as.data.frame() %>%
    pivot_longer(everything()) %>%
    mutate(
        n = 1:stan_data$N,
        sigma = post$sigma,
        z_noisy = rvar_rnorm(length(value), mean = value, sd = sigma)
    )

    return(z_predictions)
}

# Max wear linear method
getLinearPred <- function(select_obs, t_predict){
    # Function that calculates the max wear using the
    # method of Webb2020.
    max_grad <- lapply(
        1:20, 
        function(n) {
            linear_fit <- lm(stan_data$z[select_obs, n] ~ stan_data$t[select_obs] + 0)
            return(linear_fit$coefficients[[1]])
        }
    ) %>% 
    unlist() %>%
    max()

    predicted_max <- t_predict * max_grad

    return(predicted_max)
}

# leave one out checking of max wear


getCombos <- function(n_choose_from, n_min_select){
    # Generate all posible choose combinations
    combinations <- do.call(CJ, rep(list(c(0, 1)), n_choose_from))

    # Drop rows were less than n_select were chosen
    row_sums <- rowSums(combinations)
    combinations <- combinations[row_sums >= n_min_select, ]

    # Remove cases where last value is not choses (removes repitition later on)
    combinations <- combinations[combinations[[names(combinations)[n_choose_from]]] == 1, ]
    combinations <- combinations[combinations[[names(combinations)[1]]] == 1, ]

    return(combinations)
}

max_wear_checks <- list()
j <- 1

for (train_max in 5:8) {
    combos <- getCombos(train_max, 5)

    for (i in 1:nrow(combos)) {
        select_obs <- rep(FALSE, 9)
        select_obs[1:train_max] <- as.logical(combos[i, ])

        training_data <- list(
            I = sum(select_obs),
            N = stan_data$N,
            M = stan_data$M,
            t = stan_data$t[select_obs],
            z = stan_data$z[select_obs, ],
            B = stan_data$B,
            a_hat = stan_data$a_hat,
            b_hat = stan_data$b_hat
        )

        stan_fit_gp <- sampling(
            fda_noisy_GP_stan_model,
            training_data,
            chains = 4,
            iter = 2000,
            warmup = 1000,
            control = list(
                adapt_delta = 0.99, 
                max_treedepth = 14
            )
        )
        stan_fit_lm <- sampling(
            fda_LM_stan_model,
            training_data,
            chains = 4,
            iter = 2000,
            warmup = 1000,
            control = list(
                adapt_delta = 0.99, 
                max_treedepth = 14
            )
        )

        for (pred in (train_max + 1):9) {
            z_pred_gp <- genForecast_gp(
                stan_fit_gp,
                stan_data$t[pred],
                stan_data$t[train_max]
            )
            z_pred_lm <- genForecast_lm(
                stan_fit_lm,
                stan_data$t[pred]
            )

            max_wear_dist_gp <- z_pred_gp$value %>%
            as_draws_matrix() %>%
            apply(MARGIN = 1, FUN = max)
            max_wear_dist_lm <- z_pred_lm$value %>%
            as_draws_matrix() %>%
            apply(MARGIN = 1, FUN = max)

            linear_max_wear <- getLinearPred(
                select_obs, 
                stan_data$t[pred]
            )

            max_wear_checks[[j]] <- list(
                train = select_obs,
                pred_i = pred,
                predictive_dist_gp = max_wear_dist_gp,
                predictive_dist_lm = max_wear_dist_lm,
                linear_pred = linear_max_wear,
                true_max = max(stan_data$z[pred, ])
            )

            j <- j + 1
        }
    }

}

saveRDS(max_wear_checks, "ppc-obj.rds")

max_pred_plot <- lapply(
    max_wear_checks,
    function(max_pred) {
        # make title
        selected <- str_c(as.character(as.numeric(max_pred$train)), collapse = ", ")
        p_title <- str_c("[", selected,"] -> ", max_pred$pred_i)

        #p_value <- sum(max_pred$predictive_dist >= max_pred$true_max) / length(max_pred$predictive_dist)

        ggplot() +
        geom_histogram(
            data = data.frame(
                dist = max_pred$predictive_dist_gp
            ),
            aes(x = dist, y = ..density..),
            col = alpha("blue", 0.2),
            fill = alpha("blue", 0.2)
        ) +
        geom_histogram(
            data = data.frame(
                dist = max_pred$predictive_dist_lm
            ),
            aes(x = dist, y = ..density..),
            col = alpha("red", 0.2),
            fill = alpha("red", 0.2)
        ) +
        geom_vline(
            xintercept = max_pred$linear_pred,
            col = "red"
        ) +
        geom_vline(
            xintercept = max_pred$true_max,
            col = "black"
        ) +
        xlim(0, 30) +
#        geom_text_npc(
#            aes(
#                npcx = "right",
#                npcy = "top",
#                label = str_c("p = ", round(p_value, 2))
#            ),
#            size = 4
#        ) +
        ggtitle(p_title) +
        theme(plot.title = element_text(size=10))
    }
)

cowplot::plot_grid(plotlist = max_pred_plot, ncol = 6)
ggsave(
    file.path(
        "test.png"
    ),
    width = 15, height = 18
)
